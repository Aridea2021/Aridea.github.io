---
published: true
title: 对话系统论文笔记十一:emotional dialog system
category: Dialogue System
tags: 
  - DL
  - DS
  - paper reading
layout: post
---

2019.12.5 更新 Towards Empathetic Open-domain Conversation Models: a New Benchmark and Dataset 

2020.5.27 更新 GENERATING EMPATHETIC RESPONSES BY LOOKING AHEAD THE USER’S SENTIMENT

2020.10.29 更新 MOJITALK: Generating Emotional Responses at Scale Xianda

2020.11.2 更新 MoEL: Mixture of Empathetic Listeners

2020.11.2 更新 Emotional Chatting Machine: Emotional Conversation Generation with Internal and External Memory

2020.11.2 更新 Generating Responses with a Specific Emotion in Dialog

# Towards Empathetic Open-domain Conversation Models: a New Benchmark and Dataset

ACL 2019

## 总结

提出了一个新任务，如何让chatbot变得善解人意？基于数据训练出来的chatbot可能会很aggressive，或是理解不了对方谈话时的心情，比如在对话时，察觉到对方afraid/proud/faithful等情绪，应该产生对应的response，afraid就应该给予对方帮助，察觉到对面此时是proud就应该称赞等等。其实这个motivation我还觉得挺make sense的，这篇文章就基于此，提出了Empathetic的数据集和基于这个数据集的baseline。

2020.11.2 更新：这个数据集是长什么样子的？有什么特点？

# GENERATING EMPATHETIC RESPONSES BY LOOKING AHEAD THE USER’S SENTIMENT

ICASSP 2020

## 总结

以前的关注“sentiment"的对话系统研究有两种，第一种是提前给定emotion/emoji，生成对应回复；第二种是根据当前user的emotion做出不一样的回复（详情看上面那篇论文）。而这篇的作者认为第一种做法，提前给定的emotion不一定就是empathetic的，而第二种做法，如果不提前就设计好每种emotion state的回复机制，也不能产生empathetic的回复（这里我的理解可能有一点误差，因为原文也只是一句话，不好理解，并且我觉得这里有点牵强）。所以作者设计了一个Look-ahead的对话系统，具体做法是生成当前回复后，去预测当前回复的回复sentiment（即user对当前回复的sentiment，套娃？），根据此sentiment用RL去学习。

这一篇的大概思想我是懂的，但是实验部分未免太不清楚了，既然要去预测sentiment，为何没有去分析这个sentiment分类器的性能呢？而只是做了简单的automatic evaluation和human evaluation，我觉得这个sentiment不太能预测的出来，会有很大的误差。

# MOJITALK: Generating Emotional Responses at Scale Xianda

ACL 2018

## 总结

这篇文章的主要贡献点在于1.提出了一个公开的，基于emoji的（可视为对话带有emotion标签）的数据集 2.应用了2017年时候的SOTA训练了一个emotional的模型。这里的emotional主要指的是模型能够捕捉到target中的emotion信息，这里的模型还没有能力生成指定emotion label的回复。

【数据集】从Twitter上面收集了对话数据，进行了一系列的文本清洗，最后每句话都对应了一个emoji label。

【模型】1. Base模型，普通的基于attention的Seq2Seq，没啥好说的，将emoji embedding和encoder的hidden state做拼接。

2. CVAE模型，在普通CVAE模型的基础上，将emoji embedding和encoder的hidden state做拼接。
3. Reinforced CAVE，在第二个CVAE模型的基础上，训练了一个emotion分类器，用于预测生成回复的emotion label，并且有额外的emotion reward。

这个工作的主要贡献点还是在于dataset，后面有很多的工作都是基于这个Twitter-emoji数据集的。

# MoEL: Mixture of Empathetic Listeners

EMNLP-IJCNLP 2019

## 总结

以往的empathetic的对话系统可以分成两种，第一种是预测user说话时的emotion，再根据user的emotion生成empathetic的回复，这种方法一般是隐式的从ground-truth里去学习应该回复哪种emotion（模型设计者不需要知道此时此刻哪种emotion是empathetic的，而是让模型自己去学）；第二种是给定一个emotion，生成指定emotion的回复（模型设计者需要显式的给定现在的emotion，再让模型去生成）。作者认为，前者的问题在于，如果模型只有一个decoder的话，很难学到如何回复多种类型的emotion（需要对emotion进行细分，不同类型的emotion需要有不同的decoder）。后者的问题在于，很难知道什么样的emotion才是empathetic的。这个motivation其实有点问题，因为并不是数据集中的response就一定是empathetic的，也可能是toxic的回复，后者的优势在于能显式的对产生的response的emotion进行控制，而非让模型自己去学。

作者基于以上的motivation设计了一个multi-decoder的模型，模型分成三个部分：Emotion Tracker, Emotion Aware Listeners, Meta Listener，Emotion Tracker是一个transformer，接收context输出context vector，Emotion Aware Listeners包含n+1个Listener(1个shared listener和n个listeners)，Listener其实就是transformer decoder，将context vector和这些decoder的输出做处理(用的是key-value memory network)，最后每个decoder都有一个score，用来衡量此时应该选择的decoder，最后总的输出是hidden state的加权求和，而Meta Listener就是一个transformer decoder，生成最后的回复。模型的loss是MLE和选择listener的cross entropy。

作者在实验部分有对Emotion Aware Listeners的每个Listeners单独研究，在case study部分展示了一个例子，即每个Listeners对给定的input产生了不同emotion的回复。但我依然觉得这类的case study说服力不足，应该进行分析统计，而且这些Listener的名字应该是作者自己标的？在文章中也没有具体说明。

# Emotional Chatting Machine: Emotional Conversation Generation with Internal and External Memory

AAAI 2018

## 总结

作者说这是在对话系统中第一篇考虑emotion因素的工作，并且提出了一个兼顾grammer和emotion的模型，即给定一个emotion category，生成指定emotion的回复。工作的一大难点在于缺少数据集，于是作者在NLPCC的一个微博数据集上训练了一个情感分类器，再用这个分类器在STC数据集（对话数据集）上对response进行预测，构建了一个包含response情感标签的对话数据集。

文章的贡献点在于1. 提出了新任务 2.设计了ECM来生成指定emotion的回复 3.做实验表明ECM的效果好。

说实话，这篇文章的model部分我有点没看懂，具体的细节感觉跟memory network很像，但是跟它前面的model overview部分又对应不上，太难了。不过可以看出来一点，现在的工作还没有关注到empathetic这一点，而是在说，给定一个input,不同的人就有不同的反应(emotion)。

# Generating Responses with a Specific Emotion in Dialog

ACL 2019

## 总结

这篇文章相当于上一篇AAAI2018的follow，motivation很接近，有一点不一样的是，作者指出来ECM会倾向于生成"emotion-generic"(自己瞎取的)的回复，就算显式的让模型去生成某个emotion的回复，模型还是倾向于生成那些有更多训练数据的回复。

【数据集】跟ECM一样，在NLPCC的数据集上训练一个classifier，然后在STC上做分类。

【模型】文章提出两种mechanism，一种是显式的，第二种是隐式的，先构建好一个emotion words词表，对于每个emotion label而言都有若干个比较重要的emotion words。

显式的方法是在生成指定emotion时，把此emotion对应的emotion words取出来和context vector以及decoder的hidden state做attention，最后取加权和，并且在decode的时候显式的区分出emotion words和generic words。

隐式的方法是在decode时，对于当前生成的word有一个特殊的emotion classification mechanism去算一个loss，其实就跟别人训练分类器后用分类的分数做reward有点像，但是这篇文章计算的方式不同，而且也不是用classifier，用的是expected word embedding（没去细看）。

在decode时作者有些小trick，有做消融实验来证明work。

【实验】自己提出了两个emotion的自动指标，一个是用classifier（构建数据集用的）打分，一个是统计emotion words的个数。

虽然在introduction部分作者有指出ECM的不足之处，但是我在model以及experiment部分都没看到这部分的分析，只有指标上的对比。

